{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Fruits - Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data downloaded from:\n",
    "# https://www.kaggle.com/moltean/fruits/data\n",
    "# unziped and \"fruits-360\" folder placed on root (same folder as this notebook)\n",
    "\n",
    "# Define paths to both training and validation data\n",
    "train_path = 'fruits-360/Training/*'\n",
    "valid_path = 'fruits-360/Validation/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    ''' Load the images and labels to raw numpy arrays\n",
    "    Args: \n",
    "        path (str), path to folder to parse\n",
    "        images (list), empty list where array of images will be stored\n",
    "        labels (list), empty list where lables will be stored\n",
    "    return:\n",
    "        images (list, numpy array), contains the images loaded\n",
    "        labels (list, numpy array), contains the labels for each image\n",
    "    '''\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Count the unique labels in the set\n",
    "    unique_labels = []\n",
    "    \n",
    "    for folder in glob.glob(path):\n",
    "        label = folder.split('/')[-1]\n",
    "        \n",
    "        for file in glob.glob(os.path.join(folder, '*.jpg')):\n",
    "            image = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "            # imread loads an image from the specified file and returns it\n",
    "            image = cv2.resize(image, (100, 100))\n",
    "            # resize resizes the image to the specified size\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            # converts an input image from one color space to another\n",
    "            \n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        \n",
    "        # Append to unique labels in the set\n",
    "        unique_labels.append(label)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    print('%s has %s unique labels, as follows %s' %(path, len(unique_labels), unique_labels))\n",
    "    print(' ')\n",
    "    print('%s contains %s images and %s labels' %(path, len(images), len(labels)))\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruits-360/Training/* has 60 unique labels, as follows ['Training\\\\Apple Braeburn', 'Training\\\\Apple Golden 1', 'Training\\\\Apple Golden 2', 'Training\\\\Apple Golden 3', 'Training\\\\Apple Granny Smith', 'Training\\\\Apple Red 1', 'Training\\\\Apple Red 2', 'Training\\\\Apple Red 3', 'Training\\\\Apple Red Delicious', 'Training\\\\Apple Red Yellow', 'Training\\\\Apricot', 'Training\\\\Avocado', 'Training\\\\Avocado ripe', 'Training\\\\Banana', 'Training\\\\Banana Red', 'Training\\\\Cactus fruit', 'Training\\\\Carambula', 'Training\\\\Cherry', 'Training\\\\Clementine', 'Training\\\\Cocos', 'Training\\\\Dates', 'Training\\\\Granadilla', 'Training\\\\Grape Pink', 'Training\\\\Grape White', 'Training\\\\Grape White 2', 'Training\\\\Grapefruit Pink', 'Training\\\\Grapefruit White', 'Training\\\\Guava', 'Training\\\\Huckleberry', 'Training\\\\Kaki', 'Training\\\\Kiwi', 'Training\\\\Kumquats', 'Training\\\\Lemon', 'Training\\\\Lemon Meyer', 'Training\\\\Limes', 'Training\\\\Litchi', 'Training\\\\Mandarine', 'Training\\\\Mango', 'Training\\\\Maracuja', 'Training\\\\Nectarine', 'Training\\\\Orange', 'Training\\\\Papaya', 'Training\\\\Passion Fruit', 'Training\\\\Peach', 'Training\\\\Peach Flat', 'Training\\\\Pear', 'Training\\\\Pear Abate', 'Training\\\\Pear Monster', 'Training\\\\Pear Williams', 'Training\\\\Pepino', 'Training\\\\Pineapple', 'Training\\\\Pitahaya Red', 'Training\\\\Plum', 'Training\\\\Pomegranate', 'Training\\\\Quince', 'Training\\\\Raspberry', 'Training\\\\Salak', 'Training\\\\Strawberry', 'Training\\\\Tamarillo', 'Training\\\\Tangelo']\n",
      " \n",
      "fruits-360/Training/* contains 28736 images and 28736 labels\n"
     ]
    }
   ],
   "source": [
    "# TRAINING Data labels and description\n",
    "train_images, train_labels = loadData(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruits-360/Validation/* has 60 unique labels, as follows ['Validation\\\\Apple Braeburn', 'Validation\\\\Apple Golden 1', 'Validation\\\\Apple Golden 2', 'Validation\\\\Apple Golden 3', 'Validation\\\\Apple Granny Smith', 'Validation\\\\Apple Red 1', 'Validation\\\\Apple Red 2', 'Validation\\\\Apple Red 3', 'Validation\\\\Apple Red Delicious', 'Validation\\\\Apple Red Yellow', 'Validation\\\\Apricot', 'Validation\\\\Avocado', 'Validation\\\\Avocado ripe', 'Validation\\\\Banana', 'Validation\\\\Banana Red', 'Validation\\\\Cactus fruit', 'Validation\\\\Carambula', 'Validation\\\\Cherry', 'Validation\\\\Clementine', 'Validation\\\\Cocos', 'Validation\\\\Dates', 'Validation\\\\Granadilla', 'Validation\\\\Grape Pink', 'Validation\\\\Grape White', 'Validation\\\\Grape White 2', 'Validation\\\\Grapefruit Pink', 'Validation\\\\Grapefruit White', 'Validation\\\\Guava', 'Validation\\\\Huckleberry', 'Validation\\\\Kaki', 'Validation\\\\Kiwi', 'Validation\\\\Kumquats', 'Validation\\\\Lemon', 'Validation\\\\Lemon Meyer', 'Validation\\\\Limes', 'Validation\\\\Litchi', 'Validation\\\\Mandarine', 'Validation\\\\Mango', 'Validation\\\\Maracuja', 'Validation\\\\Nectarine', 'Validation\\\\Orange', 'Validation\\\\Papaya', 'Validation\\\\Passion Fruit', 'Validation\\\\Peach', 'Validation\\\\Peach Flat', 'Validation\\\\Pear', 'Validation\\\\Pear Abate', 'Validation\\\\Pear Monster', 'Validation\\\\Pear Williams', 'Validation\\\\Pepino', 'Validation\\\\Pineapple', 'Validation\\\\Pitahaya Red', 'Validation\\\\Plum', 'Validation\\\\Pomegranate', 'Validation\\\\Quince', 'Validation\\\\Raspberry', 'Validation\\\\Salak', 'Validation\\\\Strawberry', 'Validation\\\\Tamarillo', 'Validation\\\\Tangelo']\n",
      " \n",
      "fruits-360/Validation/* contains 9673 images and 9673 labels\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION Data labels and description\n",
    "valid_images, valid_labels = loadData(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the Data balanced?\n",
    "plt.subplot(121)\n",
    "plt.hist(train_labels, bins=60)\n",
    "plt.title('Labels on Training Data')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Occurences')\n",
    "plt.subplot(122)\n",
    "plt.hist(valid_labels, bins=60)\n",
    "plt.title('Labels on Validation Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a random TRAINING image and its label\n",
    "rmd=np.random.randint(0,len(train_images))\n",
    "plt.title(train_labels[rmd])\n",
    "plt.imshow(np.asarray(train_images[rmd],dtype=\"uint8\"),interpolation=\"bicubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a random VALIDATION image and its label\n",
    "rmd=np.random.randint(0,len(valid_images))\n",
    "plt.title(valid_labels[rmd])\n",
    "plt.imshow(np.asarray(valid_images[rmd],dtype=\"uint8\"),interpolation=\"bicubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation data distribution\n",
    "labels = 'Training', 'Validation'\n",
    "sizes = [len(train_images), len(valid_images)]\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "plt.title('Training vs Validation data distribution')\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to one hot\n",
    "There are 60 different classes (labels) possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToOneHot(vector, num_classes=None):\n",
    "    result = np.zeros((len(vector), num_classes), dtype='int32')\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to first convert the list of string labels to an int for the label, i.e. from 0 to 59\n",
    "# Something like results = list(map(int, results))? or a loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_onehot = convertToOneHot(train_labels, num_classes=59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "'Training input has %s, training labels has %s' %(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shapes\n",
    "inp_col = train_images.shape[1]\n",
    "inp_row = train_images.shape[2]\n",
    "inp_cha = 3\n",
    "# Variables are train_images, train_labels and valid_images, valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Input shape is %s cols by %s rows with %s channels' %(inp_col, inp_row, inp_cha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: First run with a Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image flattening for the FC network\n",
    "\n",
    "train_flatten=np.zeros([len(train_images), 45*45*3])\n",
    "for i in range(0, len(train_images)):\n",
    "    train_flatten[i]=np.reshape(train_images[i], newshape=((45*45*3),))\n",
    "    \n",
    "valid_flatten=np.zeros([len(valid_images), 45*45*3])\n",
    "for i in range(0, len(valid_images)):\n",
    "    valid_flatten[i]=np.reshape(valid_images[i], newshape=((45*45*3),))\n",
    "\n",
    "'After flattening, training input has %s and valisation input has %s' %(train_flatten.shape, valid_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 59  # Labels\n",
    "nb_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Fully Connected Network\n",
    "# No normalization, no dropout\n",
    "\n",
    "model = Sequential()\n",
    "name = 'simple_fc'\n",
    "\n",
    "model.add(Dense(300, input_dim=(inp_col*inp_row*inp_cha)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(300))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(300))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Forward Pass of untrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_flatten, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
